{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81094c5",
   "metadata": {},
   "source": [
    "# Abstractive summarizing with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e9a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isa Whitney, brother of the late Elias Whitney, D.D., Principal of the Theological College of St. George’s, was much addicted to opium. The habit grew upon him, as I understand, from some foolish freak when he was at college; for having read De Quincey’s description of his dreams and sensations, he had drenched his tobacco with laudanum in an attempt to produce the same effects. He found, as so many more have done, that the practice is easier to attain than to get rid of, and for many years he continued to be a slave to the drug, an object of mingled horror and pity to his friends and relatives. I can see him now, with yellow, pasty face, drooping lids, and pin-point pupils, all huddled in a chair, the wreck and ruin of a noble man.\n",
      "\n",
      "One night—it was in June, ’89—there came a ring to my bell, about the hour when a man gives his first yawn and glances at the clock. I sat up in my chair, and my wife laid her needle-work down in her lap and made a little face of disappointment.\n"
     ]
    }
   ],
   "source": [
    "from book_reading import Book\n",
    "\n",
    "verne=Book(\"books/Sherlock.html\")\n",
    "\n",
    "chapter=[*verne.get_paragraphs(6)]\n",
    "text=\"\\n\\n\".join(chapter[0:2])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae9593",
   "metadata": {},
   "source": [
    "## Transformers pipeline\n",
    "\n",
    "This is the general, all-default summary optoin from Huggngface. Let's see how good it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecdb2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summ_pl=pipeline(\"summarization\", framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b50652",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summ=summ_pl(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9e0939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isa Whitney, brother of the late Elias Whitney, was much addicted to opium . he drenched his tobacco with laudanum in an attempt to produce the same effects . for many years he continued to be a slave to the drug .\n"
     ]
    }
   ],
   "source": [
    "for summ in test_summ:\n",
    "    print(summ[\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83a098",
   "metadata": {},
   "source": [
    "Not very good. Maybe a bit longer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6335651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isa Whitney, brother of the late Elias Whitney, was much addicted to opium . he drenched his tobacco with laudanum in an attempt to produce the same effects . for many years he continued to be a slave to the drug .\n",
      "a man gives his first yawn and glances at the clock . his wife laid her needlework down in her lap and made a little face of disappointment .\n",
      "\"you'll have to go out,\" she said . \"you’ll have a patient!” she said. \"You’ll need to go to the hospital .\n",
      "i groaned, for . I was newly come back from a weary day . i was newly came back from an weary . day.\n",
      "our own door flew open, and a lady, clad in some dark-coloured stuff, entered the room . the door was open, a few hurried words, and then quick steps upon the linoleum .\n",
      "\"you will excuse my calling so late,\" she began . she ran forward, threw her arms about my wife's neck . \"Oh, I’m in such trouble!\" she cried .\n"
     ]
    }
   ],
   "source": [
    "for summ in summ_pl(chapter[0:6]):\n",
    "    print(summ[\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738a972",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a246567c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5ForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3feacfaf15cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5Config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/utils/dummy_pt_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         \u001b[0mrequires_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mrequires_pytorch\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nT5ForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "my_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cd21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"summarize:\"+\"\\n\\n\".join(chapter[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0a7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tokenizer(text, return_tensors='pt').input_ids\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2cc396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     3,    88,    47,     3,     9,  1144,    13,     8, 18490,\n",
       "          1949,     6,    11,   470,    47,   801,    12,   240,   294,    16]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ids = my_model.generate(input_ids)\n",
    "summary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0cbb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "<pad> he was a member of the Reform Club, and never was known to take part in\n"
     ]
    }
   ],
   "source": [
    "t5_summary = tokenizer.decode(summary_ids[0])\n",
    "print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21e824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
